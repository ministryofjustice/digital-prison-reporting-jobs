plugins {
    id 'java'
    id 'jacoco'
    id 'com.github.johnrengelman.shadow' version '8.1.1'
    id 'io.freefair.lombok' version '6.5.1'
    id 'org.sonarqube'  version '3.5.0.2730'
    id 'org.owasp.dependencycheck'  version '12.1.8'
    id 'org.gradle.java-test-fixtures'
    id 'io.micronaut.minimal.library'  version '3.7.10'
    id 'org.barfuin.gradle.jacocolog' version '3.1.0'
}

group 'uk.gov.justice'

version "${version != 'unspecified' ? version : '0.0.1-SNAPSHOT'}"

java {
    sourceCompatibility = "17"
    targetCompatibility = "17"
}

// Required because Spark accesses JVM classes that have restricted access in Java 17
// Fixes errors such as the following:
// java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x76ed5528)
// cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not
// export sun.nio.ch to unnamed module @0x76ed5528
// If you update the values then please also commit the same updates to the Intellij run configuration templates, e.g.:
// .idea/runConfigurations/_template__of_Application.xml
// .idea/runConfigurations/_template__of_JUnit.xml
// .idea/runConfigurations/_template__of_Micronaut.xml
def java17exports = [
        '--add-opens=java.base/java.lang=ALL-UNNAMED',
        '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED',
        '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED',
        '--add-opens=java.base/java.io=ALL-UNNAMED',
        '--add-opens=java.base/java.net=ALL-UNNAMED',
        '--add-opens=java.base/java.nio=ALL-UNNAMED',
        '--add-opens=java.base/java.util=ALL-UNNAMED',
        '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED',
        '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED',
        '--add-opens=java.base/sun.security.action=ALL-UNNAMED',
        '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED',
]

jacoco {
    toolVersion = "0.8.8" // Adjust the version if needed
}


repositories {
    mavenCentral()
    maven {
        url "https://aws-glue-etl-artifacts.s3.amazonaws.com/release/"
        metadataSources {
            // AWS have not deployed the Glue 5.0 dependency for local development properly. This is a known issue
            // with Glue 5.0. See https://github.com/awslabs/aws-glue-libs/issues/229
            // Previously this link (https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-libraries.html#develop-using-etl-library)
            // contained details for using this library in a Java project for local development. Since Glue 5, AWS only
            // publish details for using Docker for local development and don't publish details of developing directly
            // against the Glue dependencies.

            // This tells Gradle to only look at the JAR artifact and completely ignore the POM file because the Glue 5 POM is broken.
            artifact()
        }
    }
}

ext {
    deltaVersion = '3.3.2'
    jacksonVersion = '2.16.1'
    junitVersion = '5.8.1'
    hamcrestVersion = '2.2'
    log4jVersion = '2.23.1'
    micronautVersion = '3.8.7'
    mockitoVersion = '4.11.0'
    sparkVersion = '3.5.4'
    scalaBinary = '2.12'
    awsSdkVersion = '1.12.569' // Glue 5.0 can use 1.12.569 or 2.28.8
    glueApiVersion = '5.0.0'
    failSafeVersion = '3.3.2'
    systemLambdaVersion = '1.2.1'
    postgresVersion = '42.7.3'
    h2Version = '2.2.224'
    oracleJdbcVersion = '23.5.0.24.07'
    hikariCPVersion = '4.0.3'
    junitSystemExitVersion = '2.0.2'
}

dependencies {

    constraints {
        // org.owasp.dependencycheck needs at least this version of jackson. Other plugins pull in older versions.
        add("implementation", "com.fasterxml.jackson:jackson-bom:2.16.1")

        // org.owasp.dependencycheck needs these versions. Other plugins pull in older versions.
        add("implementation", "org.apache.commons:commons-lang3:3.14.0")
        add("implementation", "org.apache.commons:commons-text:1.11.0")
    }
    annotationProcessor 'info.picocli:picocli-codegen'

    compileOnly "org.apache.spark:spark-core_$scalaBinary:$sparkVersion"
    compileOnly "org.apache.spark:spark-sql_$scalaBinary:$sparkVersion"
    compileOnly("com.amazonaws:AWSGlueETL:$glueApiVersion") {
        // The AWS Glue team neglected to publish this dependency, but it isn't needed for us to run locally.
        // See https://github.com/awslabs/aws-glue-libs/issues/229
        exclude group: "com.amazonaws", module: "AWSGlueDILibs"
    }

    implementation "com.amazonaws:aws-java-sdk-glue:$awsSdkVersion"
    implementation "com.amazonaws:aws-java-sdk-dms:$awsSdkVersion"
    implementation "com.amazonaws:aws-java-sdk-secretsmanager:$awsSdkVersion"
    implementation "org.apache.spark:spark-avro_$scalaBinary:$sparkVersion"
    implementation "com.fasterxml.jackson.core:jackson-core:$jacksonVersion"
    implementation "com.fasterxml.jackson.core:jackson-databind:$jacksonVersion"
    implementation "com.fasterxml.jackson.datatype:jackson-datatype-jsr310:$jacksonVersion"
    implementation "com.fasterxml.jackson:jackson-bom:$jacksonVersion"
    implementation "info.picocli:picocli"
    implementation "io.micronaut.picocli:micronaut-picocli"
    implementation "io.micronaut:micronaut-jackson-databind"
    implementation "io.micronaut:micronaut-runtime:$micronautVersion"
    implementation "io.micronaut:micronaut-validation"
    implementation "jakarta.annotation:jakarta.annotation-api"
    implementation "org.apache.logging.log4j:log4j-api:$log4jVersion"
    implementation "org.apache.logging.log4j:log4j-core:$log4jVersion"
    implementation "org.apache.logging.log4j:log4j-slf4j-impl:$log4jVersion"
    implementation "io.delta:delta-spark_$scalaBinary:$deltaVersion"
    implementation "io.delta:delta-contribs_$scalaBinary:$deltaVersion"
    implementation "dev.failsafe:failsafe:$failSafeVersion"
    implementation "org.postgresql:postgresql:$postgresVersion"
    implementation "com.oracle.database.jdbc:ojdbc8:$oracleJdbcVersion"
    implementation "com.zaxxer:HikariCP:$hikariCPVersion"

    // Where spark core is pulled in transitively, ensure that it is excluded so that we
    // don't include it in the jar build by the shadowJar plugin.
    // AWS Glue provides this on the classpath so we don't need to include it.
    implementation("org.apache.spark:spark-streaming-kinesis-asl_$scalaBinary:$sparkVersion") {
      exclude group: "org.apache.spark", module: "spark-core_$scalaBinary"
    }
    implementation("org.apache.spark:spark-hive_$scalaBinary:$sparkVersion") {
      exclude group: "org.apache.spark", module: "spark-core_$scalaBinary"
    }

    testImplementation "io.micronaut.test:micronaut-test-junit5"
    testImplementation "org.junit.jupiter:junit-jupiter-api:$junitVersion"
    testImplementation "org.junit.jupiter:junit-jupiter-params:$junitVersion"
    testImplementation "org.apache.spark:spark-sql_$scalaBinary:$sparkVersion"
    // We are targetting Java 8 so must use mockito 4.x since 5.x requires Java 11 or later.
    testImplementation 'org.mockito:mockito-core:4.11.0'
    // https://mvnrepository.com/artifact/org.mockito/mockito-inline
    testImplementation 'org.mockito:mockito-inline:4.11.0'
    testImplementation "org.mockito:mockito-junit-jupiter:$mockitoVersion"
    testImplementation "org.hamcrest:hamcrest:$hamcrestVersion"
    testImplementation "com.networknt:json-schema-validator:1.0.81"
    testImplementation "com.github.stefanbirkner:system-lambda:$systemLambdaVersion"
    testImplementation "com.h2database:h2:$h2Version"
    testImplementation "com.ginsberg:junit5-system-exit:$junitSystemExitVersion"

    testRuntimeOnly "org.junit.jupiter:junit-jupiter-engine:$junitVersion"
}

sourceSets {
    integrationTest {
        java.srcDir 'src/it/java'
        resources.srcDir 'src/it/resources'
        compileClasspath += sourceSets.main.output + sourceSets.test.output
        runtimeClasspath += sourceSets.main.output + sourceSets.test.output
    }
}

configurations {
    integrationTestImplementation.extendsFrom implementation, testImplementation
    integrationTestRuntimeOnly.extendsFrom testRuntimeOnly
}

configurations.all {
    exclude group: 'org.slf4j', module: 'slf4j-reload4j'
}

// Exclude duplicate file from processing
processResources {
    exclude 'data/dms_update.json'
}

dependencies {
    integrationTestImplementation "org.junit.jupiter:junit-jupiter-api:$junitVersion"
    integrationTestRuntimeOnly "org.junit.jupiter:junit-jupiter-engine:$junitVersion"
}

// Ensure integrationTest compilation depends on test classes being available
tasks.named('compileIntegrationTestJava') {
    dependsOn tasks.named('compileTestJava')
}

// Configure the integrationTest task
tasks.register('integrationTest', Test) {
    useJUnitPlatform()
    group = LifecycleBasePlugin.VERIFICATION_GROUP
    description = 'Runs the integration tests.'

    maxHeapSize = '1024m'

    testClassesDirs = sourceSets.integrationTest.output.classesDirs
    classpath = sourceSets.integrationTest.runtimeClasspath

    jvmArgs += java17exports

    binaryResultsDirectory = file("$buildDir/integration-test-results/binary/integrationTest")

    testLogging {
        events "passed", "skipped", "failed"
        exceptionFormat = 'full'
    }
    maxParallelForks = Runtime.runtime.availableProcessors().intdiv(2) ?: 1

    reports {
        html.outputLocation = file("$buildDir/reports/integration-test")
        junitXml.outputLocation = file("$buildDir/integration-test-results")
    }

    shouldRunAfter test
}

// Configure the check task to depend on integrationTest
check.dependsOn integrationTest

// core-site.xml is excluded as it is only used for convenience when running main methods that need specific hadoop configuration locally

jar {
    exclude 'core-site.xml'
}

shadowJar {
    zip64 true
    exclude 'core-site.xml'
}

micronaut {
  version micronautVersion
}

tasks.withType(JavaCompile).configureEach {
    options.compilerArgs += [
        "-Xlint:all"
    ]
}


test {
    useJUnitPlatform()
    jacoco.includeNoLocationClasses = true
    jacoco.excludes = ['jdk.internal.*']
    testLogging {
        events "passed", "skipped", "failed"
        exceptionFormat = 'full'
    }
    maxParallelForks = Runtime.runtime.availableProcessors().intdiv(2) ?: 1
    println("\nUsing $maxParallelForks executors")
    jvmArgumentProviders.add({["-javaagent:${configurations.testRuntimeClasspath.files.find { it.name.contains('junit5-system-exit') }}"]} as CommandLineArgumentProvider)
}

jacocoTestReport {
    dependsOn test, integrationTest
    // Ensure test and integration test coverage are included
    executionData.from = files(
            "$buildDir/jacoco/test.exec",
            "$buildDir/integration-test-results/binary/integrationTest/integrationTest.exec"
    ).filter { it.exists() }

    sourceSets sourceSets.main
    sourceSets sourceSets.integrationTest

    reports {
        xml.required = false
        html.required = true
    }
}

assemble {
  dependsOn shadowJar
}

tasks.withType(JavaExec).configureEach {
    jvmArgs += java17exports
}

tasks.withType(Test).configureEach {
    jvmArgs += java17exports
}
